{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_X = \"../UCI_HAR_Dataset/train/X_train.txt\"\n",
    "PATH_TRAIN_Y = \"../UCI_HAR_Dataset/train/y_train.txt\"\n",
    "\n",
    "PATH_TEST_X = \"../UCI_HAR_Dataset/test/X_test.txt\"\n",
    "PATH_TEST_Y = \"../UCI_HAR_Dataset/test/y_test.txt\"\n",
    "\n",
    "PATH_TRAIN_SBJ = \"../UCI_HAR_Dataset/train/subject_train.txt\"\n",
    "\n",
    "PATH_TEST_SBJ = \"../UCI_HAR_Dataset/test/subject_test.txt\"\n",
    "\n",
    "PATH_FT = \"../UCI_HAR_Dataset/features.txt\"\n",
    "features = pd.read_csv(PATH_FT, sep=\" \", header=None, index_col=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "df_x_train = pd.read_fwf(PATH_TRAIN_X, header=None)\n",
    "df_x_train.rename(columns=features[1], inplace=True)\n",
    "\n",
    "y_train_col = pd.read_fwf(PATH_TRAIN_Y, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "df_X_test = pd.read_fwf(PATH_TEST_X, header=None)\n",
    "df_X_test.rename(columns=features[1], inplace=True)\n",
    "\n",
    "df_y_test = pd.read_fwf(PATH_TEST_Y, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(df_X_test)\n",
    "X = df_X_test.to_numpy()\n",
    "# X = np.random.rand(7000, 500)  # Replace with your dataset\n",
    "# y = np.array(df_y_test)\n",
    "y = df_y_test.to_numpy()\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=7)\n",
    "# y = np.random.randint(0, 6, 7000)  # Replace with your dataset labels\n",
    "print(f\"shape-y: \" + str(y.shape) + \" shape-x: \" + str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     layers.Dense(512, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "#     # layers.Dropout(0.5),\n",
    "#     # layers.Dense(256, activation='linear'),\n",
    "#     # layers.Dropout(0.5),\n",
    "#     # layers.Dense(128, activation='linear'),\n",
    "#     # layers.Dense(6, activation='softmax')\n",
    "# ])\n",
    "# model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=3, batch_size=8, validation_split=0.2)\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(pd.read_fwf(PATH_TEST_X, header=None))\n",
    "y_test_final = np.array(pd.read_fwf(PATH_TEST_Y, header=None))\n",
    "\n",
    "model.fit(x_test_final, y_test_final, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "`model.evaluate(x_test,  y_test, verbose=2)`\n",
    "\n",
    "`probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])`\n",
    "\n",
    "`probability_model(x_test[:5])`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
